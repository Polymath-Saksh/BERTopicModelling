{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic Modelling\n",
    "\n",
    "\n",
    "## Prerequisites:\n",
    "- Data File Imported/Stored in the current directory\n",
    "- Python 3.6 or above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Bertopic\n",
    "# Use '!pip install bertopic' if you are running this notebook in Google Colab\n",
    "%pip install bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "- For this data, we are doing Topic Modelling on the Abstract Data of the data corpus.<br>\n",
    "- Users can modify the last line of the next code block to change the column name of the data to be used for Topic Modelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #Import csv library\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd #Import pandas library\n",
    "#Import csv file\n",
    "pd = pd.read_csv('data.csv')\n",
    "\n",
    "#Extract abstract and time and store them in two pandas dataframes\n",
    "abstract_pd=pd['AB']\n",
    "time=pd['PY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP usage:\n",
    "- UMAP is a dimensionality reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction.\n",
    "\n",
    "### HDBSCAN usage:\n",
    "- HDBSCAN is a clustering algorithm developed by Campello, Moulavi, and Sander. It extends DBSCAN by converting it into a hierarchical clustering algorithm, and then using a technique to extract a flat clustering based in the stability of clusters.\n",
    "\n",
    "### Pipeline:\n",
    "- The pipeline is a simple way to keep track of all the steps needed to create a topic model. It is a combination of the BERTopic class, UMAP, and HDBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "#Maintain a random state (like 993) for reproducibility of the model\n",
    "#Use the UMAP algorithm to reduce the dimensionality of the documents\n",
    "umap_model = UMAP(n_neighbors=20, n_components=10, metric='cosine', low_memory=False, random_state=993)\n",
    "\n",
    "# Use the HDBSCAN algorithm to cluster the documents\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean',prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove English Stopwords from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Topic Model with embedding model, umap model and hdbscan\n",
    "\n",
    "- Keep probabilities to later check how certain the assigned topics are\n",
    "- Embedding Model used is all-MiniLM-L6-v2. Can choose other models from the list of models available in the BERTopic documentation. https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(verbose=True, embedding_model=\"all-MiniLM-L6-v2\",\n",
    "                       umap_model=umap_model, hdbscan_model=hdbscan_model,\n",
    "                       n_gram_range=(1, 3), calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to abstract data\n",
    "topics,prob = topic_model.fit_transform(abstract_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update model with stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(abstract_pd, vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Documents and Topics Closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(abstract_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intertopic Distance Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Probability Distribution\n",
    "\n",
    "- Visualise topic probability distribution of a single document, for example Document 2 (0-indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_distribution(prob[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Custom Topic Names\n",
    "- Custom topic names can be given to the topics by using the set_topic_labels() function\n",
    "\n",
    "- Pass a dictionary with the topic number as key and the topic name as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_topic_labels({0: \"Steganographic Image Data Hiding\", 1: \"Deep Image Steganalysis\", 2:\"Neural Watermark Robustness\" ,3: \"Linguistic Steganography Models\",4:\"Speech Steganalysis Algorithms\",5:\"Cognitive DNS Communication\",6:\"Video Steganography Techniques\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation with Custom Topic Names\n",
    "\n",
    "- Add a parameter 'custom_labels=True' to the visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize_barchart(custom_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Model\n",
    "\n",
    "- Topic models can be saved or retrieved using the save() and load() functions using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "model.save(\"my_model\")\n",
    "\n",
    "#Loading\n",
    "model = BERTopic.load(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving probabilities\n",
    "\n",
    "- Probabilities of data aren't saved by default, but can be saved as a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'/prob.csv',prob,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
